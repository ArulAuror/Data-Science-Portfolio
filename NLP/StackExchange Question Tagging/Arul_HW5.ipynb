{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **HW 5 – Multi-class Classification Using Dense Embeddings**"
      ],
      "metadata": {
        "id": "G-vnlxy7quPI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Pre-Processing:\n",
        "\n",
        "No Preprocessing is required. You are provided with cleaned text in column : Cleaned_text\n",
        "\n",
        "\n",
        "Split the Data to create a train, test, and validation split.\n",
        "\n",
        "-\tUse 80% observations for the train set, 10%  for the validation set, and 10 % for the test set.\n",
        "\n",
        "Hyperparameters and Network:\n",
        "\n",
        "-\tFor creating vocab use a min frequency of 5\n",
        "-\tYour Network should have the following layers\n",
        "\n",
        "Embeddinglayer → Hidden_Layer1 → Dropout_Layer1 → BatchNorn_Layer1 → Hidden_Layer2 → DropoutLayer2 → BatchNorm_Layer2 \n",
        "\n",
        "-\tEmbedding dimension - 300\n",
        "-\tNeurons in Hidden_Layer 1 - 200\n",
        "-\tNeurons in Hidden_Layer 2- 100\n",
        "-\tDropout probability for  Dropout_Layer1 → 0.5\n",
        "-\tDropout probability for  Dropout_Layer2 → 0.5\n",
        "-\tLoss Function → CrossEntropy\n",
        "-\tBatch_size - 256\n",
        "-\tLearning_rate - 0.2\n",
        "-\tNumber of epochs = 20\n",
        "-\tUse early stopping with the patience of 5\n",
        "-\tWeight_decay = 0\n",
        "-\tActivation function for hidden layer = ReLU\n",
        "-\tOptimizer - SGD (Make sure you use SGD and not Adam)\n"
      ],
      "metadata": {
        "id": "hmoIhox9qz8u"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTd5DfBAqbc6"
      },
      "source": [
        "# Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6dMS3KisSRLT"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install wandb --upgrade -qq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "GdkdBjeeTzyg",
        "outputId": "73dff58f-e1a2-458e-ac30-bc44d99b6a0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "CQQbjmDl5Got"
      },
      "outputs": [],
      "source": [
        "# Import random function\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchtext.vocab import  vocab\n",
        "\n",
        "import wandb\n",
        "import spacy\n",
        "#import custom_preprocessor as cp\n",
        "\n",
        "import random\n",
        "from datetime import datetime\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import joblib\n",
        "from collections import Counter\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "kEDlrfWpSCHc"
      },
      "outputs": [],
      "source": [
        "# Fix seed value\n",
        "SEED = 2345\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "omgjHGvS2VBQ"
      },
      "outputs": [],
      "source": [
        "data_folder = Path('/content/drive/MyDrive/Lec10/HW5/Data')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "AfxXCoF44R5q"
      },
      "outputs": [],
      "source": [
        "save_model_folder = Path('/content/drive/MyDrive/NLP/models')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0CyZzobQoT_"
      },
      "source": [
        "We will be using W&B for visualization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "faY9UaHhQkb3",
        "outputId": "34ffca75-aec0-45cb-e480-2be5241f823d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# Login to W&B\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTrbf15aROgj"
      },
      "source": [
        "## Train/Test/Valid Dataset for Preprocessed data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_file = data_folder/ 'multiclass_hw_cleaned.csv'"
      ],
      "metadata": {
        "id": "y_fUe6ArrRes"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessed data\n",
        "cleaned_data = pd.read_csv(cleaned_file, index_col=0)"
      ],
      "metadata": {
        "id": "mRx55givudvj"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "RXYsyw4r7OGb",
        "outputId": "58127b7a-62f5-4d7a-fe25-b87fbc1018f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of cleaned data set is : (188878, 5)\n"
          ]
        }
      ],
      "source": [
        "print(f'Shape of cleaned data set is : {cleaned_data.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "wNs_rXzpvL7f",
        "outputId": "fafc572d-f917-4d34-9070-6cb43b68b4b4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               Title  \\\n",
              "0            detail disclosure indicator on UIButton   \n",
              "1           hello world fails to show up in emulator   \n",
              "2  Why is JSHint throwing a \"possible strict viol...   \n",
              "3       Programmatically Make Bound Column Invisible   \n",
              "4  More than one EditText - not getting focus, no...   \n",
              "\n",
              "                                                Body  \\\n",
              "0  <p>Is there a simple way to place a detail dis...   \n",
              "1  <p>I followed Hello World tutorial exactly.  E...   \n",
              "2  <p>Trying to validate some Javascript in JsHin...   \n",
              "3  <p>I'm trying to make a data bound column invi...   \n",
              "4  <p>The home screen of my Android application h...   \n",
              "\n",
              "                                        cleaned_text        Tags  \\\n",
              "0  detail disclosure indicator uibutton simple wa...      iphone   \n",
              "1  hello world fail emulator follow hello world t...     android   \n",
              "2  jshint throw possible strict violation line tr...  javascript   \n",
              "3  programmatically bound column invisible try da...     asp.net   \n",
              "4  edittext get focus soft keyboard android home ...     android   \n",
              "\n",
              "   Tag_Number_final  \n",
              "0                 8  \n",
              "1                 4  \n",
              "2                 3  \n",
              "3                 9  \n",
              "4                 4  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d8e0b633-5dff-4a7a-8d8d-3572181d7e96\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Title</th>\n",
              "      <th>Body</th>\n",
              "      <th>cleaned_text</th>\n",
              "      <th>Tags</th>\n",
              "      <th>Tag_Number_final</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>detail disclosure indicator on UIButton</td>\n",
              "      <td>&lt;p&gt;Is there a simple way to place a detail dis...</td>\n",
              "      <td>detail disclosure indicator uibutton simple wa...</td>\n",
              "      <td>iphone</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>hello world fails to show up in emulator</td>\n",
              "      <td>&lt;p&gt;I followed Hello World tutorial exactly.  E...</td>\n",
              "      <td>hello world fail emulator follow hello world t...</td>\n",
              "      <td>android</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Why is JSHint throwing a \"possible strict viol...</td>\n",
              "      <td>&lt;p&gt;Trying to validate some Javascript in JsHin...</td>\n",
              "      <td>jshint throw possible strict violation line tr...</td>\n",
              "      <td>javascript</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Programmatically Make Bound Column Invisible</td>\n",
              "      <td>&lt;p&gt;I'm trying to make a data bound column invi...</td>\n",
              "      <td>programmatically bound column invisible try da...</td>\n",
              "      <td>asp.net</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>More than one EditText - not getting focus, no...</td>\n",
              "      <td>&lt;p&gt;The home screen of my Android application h...</td>\n",
              "      <td>edittext get focus soft keyboard android home ...</td>\n",
              "      <td>android</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d8e0b633-5dff-4a7a-8d8d-3572181d7e96')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d8e0b633-5dff-4a7a-8d8d-3572181d7e96 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d8e0b633-5dff-4a7a-8d8d-3572181d7e96');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "9RFTtWvX7Vwr"
      },
      "outputs": [],
      "source": [
        "# We are interested in cleaned_text and Tag_Number_final columns\n",
        "X, y = cleaned_data['cleaned_text'].values, cleaned_data['Tag_Number_final'].values"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # 80% observations for  train, 10%  for validation, and 10 % for test\n",
        "\n",
        " # Step1 - Split entire dataset into 90% train and 10% test\n",
        " X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
        " # Step1 - Split 90% train further into 10% test. So finally remaining is 80% train\n",
        " X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.1, random_state=42)"
      ],
      "metadata": {
        "id": "L4MxPlsOuTOT"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsYaM3_ftTgi"
      },
      "source": [
        "## Custom Dataset Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "kFmE7lcjCuSM"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, X, y):\n",
        "        self.X = np.array(X)\n",
        "        self.y = y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        text = self.X[idx]\n",
        "        labels = self.y[idx]\n",
        "        sample = (text, labels)\n",
        "        \n",
        "        return sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "bDesWA-Ssmk_"
      },
      "outputs": [],
      "source": [
        "trainset = CustomDataset(X_train,y_train)\n",
        "validset = CustomDataset(X_valid,y_valid)\n",
        "testset = CustomDataset(X_test,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "T-lZrEottGtH",
        "outputId": "474ee577-e95d-40b5-9598-39bd0a72ae46"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array(['download audio file non direct link want implement download manager let form post method site click submit button site send post datum server download start content response form want download datum user click submit button help thank'],\n",
              "       dtype=object), array([8]))"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "trainset.__getitem__([11])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XoEVe7eGtY7U"
      },
      "source": [
        "## Create Vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "LRLHO-M1to6q"
      },
      "outputs": [],
      "source": [
        "def create_vocab(dataset, min_freq):\n",
        "  counter = Counter()\n",
        "  for (text, _) in dataset:\n",
        "    counter.update(str(text).split())\n",
        "  my_vocab = vocab(counter, min_freq=min_freq)\n",
        "  my_vocab.insert_token('<unk>', 0)\n",
        "  my_vocab.set_default_index(0)\n",
        "  return my_vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "wNUi_aNctkAo"
      },
      "outputs": [],
      "source": [
        "# create vocab based on trainset using a min frequency of 5\n",
        "stack_exchange_vocab = create_vocab(trainset, min_freq = 5)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(stack_exchange_vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ask8H1QJJMZK",
        "outputId": "4929e22b-d445-4311-a413-8441f6ef9d9d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "85311"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "collapsed": true,
        "id": "eyaeFqCsuRTQ",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "eec2f088-616a-4b33-b12f-e6bac0418ea6",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<unk>', 'line', 'execute', 'javascript', 'get']"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "stack_exchange_vocab.get_itos()[0:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojvSMWR5u-LU"
      },
      "source": [
        "## Collate_fn for Data Loaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "cdBKJlVmvB-9"
      },
      "outputs": [],
      "source": [
        "# Creating a lambda function objects that will be used to get the indices of words from vocab\n",
        "text_pipeline = lambda x: [stack_exchange_vocab[token] for token in str(x).split()]\n",
        "label_pipeline = lambda x: int(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "cL1TZVthvIT2"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "We know that input to the embedding layers are indices of words from the vocab.\n",
        "The collate_batch() accepts batch of data and gets the indices of text from vocab and returns the same\n",
        "We will include this collate_batch() in collat_fn attribute of DataLoader.\n",
        "So it will create a batch of data containing indices of words and corresponding labels.\n",
        "But for EmbeddingBag we need one more extra parameter, that is offset.\n",
        "offsets determines the starting index position of each bag (sequence) in input.\n",
        "'''\n",
        "def collate_batch(batch):\n",
        "    label_list, text_list, offsets = [], [], [0]\n",
        "    for (_text, _label) in batch:\n",
        "         label_list.append(label_pipeline(_label))\n",
        "         processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n",
        "         text_list.append(processed_text)\n",
        "         offsets.append(processed_text.size(0))\n",
        "    label_list = torch.tensor(label_list, dtype=torch.int64)\n",
        "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
        "    text_list = torch.cat(text_list)\n",
        "    return text_list, label_list, offsets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZB8Kd5wCCuSN"
      },
      "source": [
        "## **Check Data Loader**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "qZ8DLatvCuSN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "1c907015-fce9-468d-90a5-c91723f153a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ],
      "source": [
        "batch_size=2\n",
        "check_loader= torch.utils.data.DataLoader(dataset=trainset,\n",
        "                                        batch_size=batch_size,\n",
        "                                        shuffle=True,\n",
        "                                        collate_fn=collate_batch,\n",
        "                                        num_workers=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "hc49Kv46HMqJ",
        "outputId": "c5b2ea68-7707-4ec3-c045-395c08ea46b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([6, 0]) tensor([  978,   525,  5937,  4948,   661,  1237,     9,    86,   412,   337,\n",
            "            8,    18,    18,   978,   525,  5937,  4948,   123,   234,    90,\n",
            "          316,     0,   416,  4616,  1512,   395,  1259,  2010,   395, 14092,\n",
            "           12,     0,  1259,  2010,   395,  2097,    12,     0,    63,  4231,\n",
            "         5785,  4229,   163,    90,    86,    90,  1598,    66,   829,   820,\n",
            "          130,   116,  4229,  1824,  3113,   179,   103,   115,   157,     8,\n",
            "          534,   879,   810,  4008,   180,   559,  1258,  9883,   164,  2167,\n",
            "        38507,   595,   559,     0,   559,   224,    44,   278,   278,  2058,\n",
            "          278,  1467,   278,  1467, 10053,   278,  1257,   278,  2159, 20668,\n",
            "            0,   278,   531,  2110,     0,   278,   141,   216,   559,   965,\n",
            "           45,  1331,  9852,    40,   782,   829,  6737,  2167,   559,   108,\n",
            "          649,   559,  7644,   180,  1399,   519,  2167, 38507,   830,   595,\n",
            "          830,     4,  1253,    18,  2167, 38507,   180,  2375,     9,   180,\n",
            "          559,  9883,   164,  2167,   325,  1436,  5902,   830,   100,   595,\n",
            "         1258, 38507, 55429,   557]) tensor([ 0, 63])\n"
          ]
        }
      ],
      "source": [
        "for text, label, offsets in check_loader:\n",
        "  print(label, text, offsets)\n",
        "  break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5PIh63mSCuSN"
      },
      "source": [
        "# Model \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "6OWsVNqmfQ9a"
      },
      "outputs": [],
      "source": [
        "class MLPCustom(nn.Module):\n",
        "  def __init__(self, vocab_size, hidden_sizes_list, dprobs_list, batchnorm_binary, output_dim, non_linearity):\n",
        "\n",
        "    \n",
        "\n",
        "    self.vocab_size = vocab_size\n",
        "    \n",
        "\n",
        "    self.hidden_sizes_list = hidden_sizes_list # hidden_sizes = [emb_dim, hidden_dim1, hidden_dim2, .....hidden_dimn] # n + 1 elements\n",
        "    self.dprobs_list = dprobs_list # dpropb =[prob1, prob2....probn] # n elements\n",
        "    self.batchnorm_binary  = batchnorm_binary  # True or False\n",
        "    self.output_dim = output_dim\n",
        "    self.non_linearity = non_linearity\n",
        "    \n",
        "\n",
        "    super().__init__()\n",
        "\n",
        "    # embedding_layer\n",
        "    self.embedding_layer = nn.EmbeddingBag(self.vocab_size, self.hidden_sizes_list[0])\n",
        "\n",
        "    # Creation of 3 empty lists of layers in pytorch (ModuleLists)\n",
        "    # hidden layers\n",
        "    self.hidden_layers = nn.ModuleList()\n",
        "\n",
        "    # dropout layers\n",
        "    self.dropout_layers = nn.ModuleList()\n",
        "\n",
        "    # batchnorm layers\n",
        "    self.batchnorm_layers = nn.ModuleList()\n",
        "\n",
        "    for k in range(len(self.hidden_sizes_list)-1):\n",
        "      self.hidden_layers.append(nn.Linear(self.hidden_sizes_list[k], self.hidden_sizes_list[k+1])) \n",
        "      self.dropout_layers.append(nn.Dropout(p=self.dprobs_list[k]))\n",
        "\n",
        "      if self.batchnorm_binary:\n",
        "        self.batchnorm_layers.append(nn.BatchNorm1d(self.hidden_sizes_list[k+1], momentum=0.9))\n",
        "\n",
        "    self.output_layer = nn.Linear(self.hidden_sizes_list[-1], self.output_dim)\n",
        "\n",
        "   \n",
        "\n",
        "  def forward(self, input, offsets):\n",
        "    x = self.embedding_layer(input, offsets)\n",
        "    for  k in range(len(self.hidden_sizes_list)-1):\n",
        "      x =  self.non_linearity(self.hidden_layers[k](x))\n",
        "      if self.batchnorm_binary:\n",
        "        x = self.batchnorm_layers[k](x)\n",
        "      x= self.dropout_layers[k](x)\n",
        "\n",
        "    x = self.output_layer(x)\n",
        "    # we are not using softmax function in the forward passs\n",
        "    # nn.crossentropy loss (which we will use to define our loss) combines  nn.LogSoftmax() and nn.NLLLoss() in one single class\n",
        "    return x "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ry-7lHYVPlPP"
      },
      "source": [
        "# Training Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3GdVoTjh7YD"
      },
      "source": [
        "## Training Epoch "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "Pv4x22lZMn5p"
      },
      "outputs": [],
      "source": [
        "def train(train_loader, model, optimizer, loss_function, log_batch, log_interval, grad_clipping, max_norm):\n",
        "\n",
        "  \"\"\" \n",
        "  Function for training the model in each epoch\n",
        "  Input: iterator for train dataset, initial weights and bias, epochs, learning rate.\n",
        "  Output: final weights, bias, train loss, train accuracy\n",
        "  \"\"\"\n",
        "  # initilalize variables as global\n",
        "  # these counts will be updated every epoch\n",
        "  global example_ct_train\n",
        "  global batch_ct_train\n",
        "\n",
        "  # Training Loop loop\n",
        "  # Initialize train_loss at the he start of the epoch\n",
        "  running_train_loss = 0\n",
        "  running_train_correct = 0\n",
        "  \n",
        "  # put the model in training mode\n",
        "  model.train()\n",
        "\n",
        "  # Iterate on batches from the dataset using train_loader\n",
        "  for inputs, targets, offsets in train_loader:\n",
        "    \n",
        "    # move inputs and outputs to GPUs\n",
        "    inputs = inputs.to(device)\n",
        "    targets = targets.to(device)\n",
        "    offsets = offsets.to(device)\n",
        "\n",
        "    # Forward pass\n",
        "    output = model(inputs, offsets)\n",
        "    loss = loss_function(output, targets)\n",
        "\n",
        "    # Correct prediction\n",
        "    y_pred = torch.argmax(output, dim = 1)\n",
        "    correct = torch.sum(y_pred == targets)\n",
        "\n",
        "    example_ct_train +=  len(targets)\n",
        "    batch_ct_train += 1\n",
        "\n",
        "    # set gradients to zero \n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Backward pass\n",
        "    loss.backward()\n",
        "\n",
        "    # Gradient Clipping\n",
        "    if grad_clipping:\n",
        "      nn.utils.clip_grad_norm_(model.parameters(), max_norm=max_norm, norm_type=2)\n",
        "\n",
        "    # Update parameters using their gradient\n",
        "    optimizer.step()\n",
        "          \n",
        "    # Add train loss of a batch \n",
        "    running_train_loss += loss.item()\n",
        "\n",
        "    # Add Corect counts of a batch\n",
        "    running_train_correct += correct\n",
        "\n",
        "    # log batch loss and accuracy\n",
        "    if log_batch:\n",
        "      if ((batch_ct_train + 1) % log_interval) == 0:\n",
        "        wandb.log({f\"Train Batch Loss  :\": loss})\n",
        "        wandb.log({f\"Train Batch Acc :\": correct/len(targets)})\n",
        "\n",
        "  \n",
        "  # Calculate mean train loss for the whole dataset for a particular epoch\n",
        "  train_loss = running_train_loss/len(train_loader)\n",
        "\n",
        "\n",
        "\n",
        "  # Calculate accuracy for the whole dataset for a particular epoch\n",
        "  train_acc = running_train_correct/len(train_loader.dataset)\n",
        "\n",
        "  return train_loss, train_acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aic8wk5niFCz"
      },
      "source": [
        "## Validation/Test Epoch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "pHP1WKDessiI"
      },
      "outputs": [],
      "source": [
        "def valid(loader, model, optimizer, loss_function, log_batch, log_interval):\n",
        "\n",
        "  \"\"\" \n",
        "  Function for training the model and plotting the graph for train & valid loss vs epoch.\n",
        "  Input: iterator for train dataset, initial weights and bias, epochs, learning rate, batch size.\n",
        "  Output: final weights, bias and train loss and valid loss for each epoch.\n",
        "  \"\"\"\n",
        "\n",
        "  # initilalize variables as global\n",
        "  # these counts will be updated every epoch\n",
        "  global example_ct_valid\n",
        "  global batch_ct_valid\n",
        "\n",
        "  # Validation loop\n",
        "  # Initialize train_loss at the he strat of the epoch\n",
        "  running_valid_loss = 0\n",
        "  running_valid_correct = 0\n",
        "  \n",
        "  # put the model in evaluation mode\n",
        "  model.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for inputs, targets, offsets in loader:\n",
        "      \n",
        "      # move inputs and outputs to GPUs\n",
        "      inputs = inputs.to(device)\n",
        "      targets = targets.to(device)\n",
        "      offsets = offsets.to(device)\n",
        "\n",
        "      # Forward pass\n",
        "      output = model(inputs, offsets)\n",
        "      loss = loss_function(output,targets)\n",
        "\n",
        "      # Correct Predictions\n",
        "      y_pred = torch.argmax(output, dim = 1)\n",
        "      correct = torch.sum(y_pred == targets)\n",
        "\n",
        "      # count of images and batches\n",
        "      example_ct_valid +=  len(targets)\n",
        "      batch_ct_valid += 1\n",
        "\n",
        "      # Add valid loss of a batch \n",
        "      running_valid_loss += loss.item()\n",
        "\n",
        "      # Add correct count for each batch\n",
        "      running_valid_correct += correct\n",
        "\n",
        "      # log batch loss and accuracy\n",
        "      if log_batch:\n",
        "        if ((batch_ct_valid + 1) % log_interval) == 0:\n",
        "          wandb.log({f\"Valid Batch Loss  :\": loss})\n",
        "          wandb.log({f\"Valid Batch Accuracy :\": correct/len(targets)})\n",
        "\n",
        "\n",
        "    # Calculate mean valid loss for the whole dataset for a particular epoch\n",
        "    valid_loss = running_valid_loss/len(valid_loader)\n",
        "\n",
        "    # scheduler step\n",
        "    # scheduler.step(valid_loss)\n",
        "    # scheduler.step()\n",
        "\n",
        "    # Calculate accuracy for the whole dataset for a particular epoch\n",
        "    valid_acc = running_valid_correct/len(valid_loader.dataset)\n",
        "    \n",
        "  return valid_loss, valid_acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwF70eqE6n_v"
      },
      "source": [
        "##  Model Training Loop\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "KeCKVgg-5FiZ"
      },
      "outputs": [],
      "source": [
        "def train_loop(train_loader, valid_loader, model, loss_function, optimizer, epochs, device, patience, early_stopping,\n",
        "               file_model):\n",
        "\n",
        "  '''\n",
        "  model: specify your model for training\n",
        "  criterion: loss function \n",
        "  optimizer: optimizer like SGD , ADAM etc.\n",
        "  train loader: function to carete batches for training data\n",
        "  valid loader : function to create batches for valid data set\n",
        "  file_model : specify file name for saving your model. This way we can upload the model weights from file. We will not to run model again.\n",
        "  \n",
        "\n",
        "  '''\n",
        "  # Create lists to store train and valid loss at each epoch\n",
        "\n",
        "  train_loss_history = []\n",
        "  valid_loss_history = []\n",
        "  train_acc_history = []\n",
        "  valid_acc_history = []\n",
        "  delta = 0\n",
        "  best_score = None\n",
        "  valid_loss_min = np.Inf\n",
        "  counter_early_stop=0\n",
        "  early_stop=False\n",
        "\n",
        "\n",
        "  # Iterate for the given number of epochs\n",
        "  for epoch in range(epochs):\n",
        "    t0 = datetime.now()\n",
        "    # Get train loss and accuracy for one epoch\n",
        "\n",
        "    train_loss, train_acc = train(train_loader, model, optimizer, loss_function, \n",
        "                                  wandb.config.LOG_BATCH, wandb.config.LOG_INTERVAL,\n",
        "                                  wandb.config.GRAD_CLIPPING, wandb.config.MAX_NORM)\n",
        "    valid_loss, valid_acc = valid(valid_loader, model, optimizer, loss_function,\n",
        "                                    wandb.config.LOG_BATCH, wandb.config.LOG_INTERVAL)\n",
        "\n",
        "    dt = datetime.now() - t0\n",
        "\n",
        "    # Save history of the Losses and accuracy\n",
        "    train_loss_history.append(train_loss)\n",
        "    train_acc_history.append(train_acc)\n",
        "    valid_loss_history.append(valid_loss)\n",
        "    valid_acc_history.append(valid_acc)\n",
        "\n",
        "    if early_stopping:\n",
        "      score = -valid_loss\n",
        "      if best_score is None:\n",
        "        best_score=score\n",
        "        print(f'Validation loss has decreased ({valid_loss_min:.6f} --> {valid_loss:.6f}). Saving Model...')\n",
        "        torch.save(model.state_dict(), file_model)\n",
        "        valid_loss_min = valid_loss\n",
        "\n",
        "      elif score < best_score + delta:\n",
        "        counter_early_stop += 1\n",
        "        print(f'Early stoping counter: {counter_early_stop} out of {patience}')\n",
        "        if counter_early_stop > patience:\n",
        "          early_stop = True\n",
        "\n",
        "      \n",
        "      else:\n",
        "        best_score = score\n",
        "        print(f'Validation loss has decreased ({valid_loss_min:.6f} --> {valid_loss:.6f}). Saving model...')\n",
        "        torch.save(model.state_dict(), file_model)\n",
        "        counter_early_stop=0\n",
        "        valid_loss_min = valid_loss\n",
        "\n",
        "      if early_stop:\n",
        "        print('Early Stopping')\n",
        "        break\n",
        "\n",
        "    else:\n",
        "\n",
        "      score = -valid_loss\n",
        "      if best_score is None:\n",
        "        best_score=score\n",
        "        print(f'Validation loss has decreased ({valid_loss_min:.6f} --> {valid_loss:.6f}). Saving Model...')\n",
        "        torch.save(model.state_dict(), file_model)\n",
        "        valid_loss_min = valid_loss\n",
        "\n",
        "      elif score < best_score + delta:\n",
        "        print(f'Validation loss has not decreased ({valid_loss_min:.6f} --> {valid_loss:.6f}). Not Saving Model...')\n",
        "      \n",
        "      else:\n",
        "        best_score = score\n",
        "        print(f'Validation loss has decreased ({valid_loss_min:.6f} --> {valid_loss:.6f}). Saving model...')\n",
        "        torch.save(model.state_dict(), file_model)\n",
        "        valid_loss_min = valid_loss\n",
        "\n",
        "\n",
        "\n",
        "    # Log the train and valid loss to W&B\n",
        "    wandb.log({f\"Train epoch Loss :\": train_loss, f\"Valid epoch Loss :\": valid_loss })\n",
        "    wandb.log({f\"Train epoch Acc :\": train_acc, f\"Valid epoch Acc :\": valid_acc})\n",
        "\n",
        "\n",
        "\n",
        "    # Print the train loss and accuracy for given number of epochs, batch size and number of samples\n",
        "    print(f'Epoch : {epoch+1} / {epochs}')\n",
        "    print(f'Time to complete {epoch+1} is {dt}')\n",
        "    # print(f'Learning rate: {scheduler._last_lr[0]}')\n",
        "    print(f'Train Loss: {train_loss : .4f} | Train Accuracy: {train_acc * 100 : .4f}%')\n",
        "    print(f'Valid Loss: {valid_loss : .4f} | Valid Accuracy: {valid_acc * 100 : .4f}%')\n",
        "    print()\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "  return train_loss_history, train_acc_history, valid_loss_history, valid_acc_history\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yte1HzNniWlr"
      },
      "source": [
        "#Model Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fLa11d5rPZv"
      },
      "source": [
        "## **Meta data**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "F3ISekWSV84a"
      },
      "outputs": [],
      "source": [
        "hyperparameters = dict(\n",
        "    \n",
        "    HIDDEN_SIZES_LIST = [300] + [200] + [100],  # 300 = embed_dim, 200- hidden_dim1 , 100 -hidden_dim2\n",
        "    DPROBS_LIST = [0.5] + [0.5], # 0.5 - dropout after first hidden layer layer, 0.8 dropout after  second hidden layer\n",
        "    BATCHNORM_BINARY = True,\n",
        "    \n",
        "    \n",
        "    VOCAB_SIZE = len(stack_exchange_vocab),\n",
        "    OUTPUT_DIM = 10,\n",
        "\n",
        "    EPOCHS = 20,\n",
        "    \n",
        "    BATCH_SIZE = 256,\n",
        "    LEARNING_RATE = 0.2,\n",
        "    DATASET=\"stack_exchange\",\n",
        "    ARCHITECTUREe=\"Embed_2_hidden_layers\",\n",
        "    LOG_INTERVAL = 25,\n",
        "    LOG_BATCH = True,\n",
        "    FILE_MODEL = save_model_folder/'stack_exchange_2_hidden_layers.pt',\n",
        "    GRAD_CLIPPING = False,\n",
        "    MAX_NORM = 0,\n",
        "    MOMENTUM = 0,\n",
        "    PATIENCE = 5,\n",
        "    EARLY_STOPPING = True,\n",
        "    SCHEDULER_FACTOR = 0,\n",
        "    SCHEDULER_PATIENCE = 0,\n",
        "    WEIGHT_DECAY = 0\n",
        "   )\n",
        "\n",
        "# Activation function for hidden layer \n",
        "non_linearity = F.relu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xH25I8Pikqpb"
      },
      "source": [
        "## Initialize wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "9Zp9fDrAheXc",
        "outputId": "318c21f1-7b11-401d-cf69-f8607f69feb9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33marulchak\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.12.14"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220410_221011-2rohzf2j</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/arulchak/NLP_MLP_Stack_Exchange/runs/2rohzf2j\" target=\"_blank\">Embed_2_hidden_layers</a></strong> to <a href=\"https://wandb.ai/arulchak/NLP_MLP_Stack_Exchange\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/arulchak/NLP_MLP_Stack_Exchange/runs/2rohzf2j?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7f3c28c8be90>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "wandb.init(name = 'Embed_2_hidden_layers', project = 'NLP_MLP_Stack_Exchange', config = hyperparameters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "Y1IZOBtaS2st"
      },
      "outputs": [],
      "source": [
        "# add non_linearity to config file\n",
        "wandb.config.NON_LINEARITY = non_linearity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9DjhWa3k-Gk"
      },
      "source": [
        "## Specify Dataloader, Loss_function, Model, Optimizer, Weight Initialization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "XyTAuL2BpO_Q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "f2756340-aa63-4e00-b7a3-aa89d4827877"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ],
      "source": [
        "# Fix seed value\n",
        "from datetime import datetime\n",
        "SEED = 2345\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "# Data Loader\n",
        "train_loader = torch.utils.data.DataLoader(trainset, batch_size=wandb.config.BATCH_SIZE, shuffle = True, \n",
        "                                           collate_fn=collate_batch, num_workers = 4)\n",
        "valid_loader = torch.utils.data.DataLoader(validset, batch_size=wandb.config.BATCH_SIZE, shuffle = False, \n",
        "                                           collate_fn=collate_batch,  num_workers = 4)\n",
        "test_loader = torch.utils.data.DataLoader(testset, batch_size=wandb.config.BATCH_SIZE,   shuffle = False, \n",
        "                                          collate_fn=collate_batch,  num_workers = 4)\n",
        "\n",
        "# cross entropy loss function\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "\n",
        "# use GPUs\n",
        "#device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "device ='cpu'\n",
        "\n",
        "# model \n",
        "model_stack_exchange = MLPCustom(wandb.config.VOCAB_SIZE, wandb.config.HIDDEN_SIZES_LIST, wandb.config.DPROBS_LIST, wandb.config.BATCHNORM_BINARY, \n",
        "           wandb.config.OUTPUT_DIM, non_linearity)\n",
        "model_stack_exchange.to(device)\n",
        "\n",
        "def init_weights(m):\n",
        "  if type(m) == nn.Linear:\n",
        "      torch.nn.init.kaiming_normal_(m.weight)\n",
        "      torch.nn.init.zeros_(m.bias)\n",
        "        \n",
        "# apply initialization recursively  to all modules\n",
        "model_stack_exchange.apply(init_weights)\n",
        "\n",
        "# Intialize stochiastic gradient descent as optimizer\n",
        "optimizer = torch.optim.SGD(model_stack_exchange.parameters(), lr = wandb.config.LEARNING_RATE, weight_decay=wandb.config.WEIGHT_DECAY)\n",
        "\n",
        "wandb.config.optimizer = optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPDnF9JbSHdX"
      },
      "source": [
        "## Sanity Check\n",
        "- Check the loss without any training. For Cross entropy the expected value will be log(number of classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "GWkFxtEqSKlW",
        "outputId": "00dd71b8-efbb-428c-f63a-3866eac3b8f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual loss: 2.3519251346588135\n",
            "Expected Theoretical loss: 0.6931471805599453\n"
          ]
        }
      ],
      "source": [
        "# Fix seed value\n",
        "SEED = 2345\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "for input, targets, offsets in train_loader:\n",
        "  \n",
        "  # move inputs and outputs to GPUs\n",
        "  input = input.to(device)\n",
        "  targets = targets.to(device)\n",
        "  offsets = offsets.to(device)\n",
        "  model_stack_exchange.eval()\n",
        "  # Forward pass\n",
        "  output = model_stack_exchange(input, offsets)\n",
        "  loss = loss_function(output, targets)\n",
        "  print(f'Actual loss: {loss}')\n",
        "  break\n",
        "\n",
        "print(f'Expected Theoretical loss: {np.log(2)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "htWT1-Nhlw3m"
      },
      "source": [
        "## Train Model and Save best model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "MwnGtxo3B2nD",
        "outputId": "bcf34dae-8e0a-462b-b040-3c8ce7c868e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<wandb.wandb_torch.TorchGraph at 0x7f3c272c2950>]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "wandb.watch(model_stack_exchange, log = 'all', log_freq=25, log_graph=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "QyAaOEg5DdKp",
        "outputId": "2b1eac30-efa3-44fb-c7f8-c290b201313e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss has decreased (inf --> 0.728324). Saving Model...\n",
            "Epoch : 1 / 20\n",
            "Time to complete 1 is 0:01:29.010856\n",
            "Train Loss:  1.1455 | Train Accuracy:  63.1397%\n",
            "Valid Loss:  0.7283 | Valid Accuracy:  77.2810%\n",
            "\n",
            "Validation loss has decreased (0.728324 --> 0.685458). Saving model...\n",
            "Epoch : 2 / 20\n",
            "Time to complete 2 is 0:01:30.416707\n",
            "Train Loss:  0.8350 | Train Accuracy:  73.4056%\n",
            "Valid Loss:  0.6855 | Valid Accuracy:  78.3281%\n",
            "\n",
            "Validation loss has decreased (0.685458 --> 0.639434). Saving model...\n",
            "Epoch : 3 / 20\n",
            "Time to complete 3 is 0:01:28.406942\n",
            "Train Loss:  0.7670 | Train Accuracy:  75.7110%\n",
            "Valid Loss:  0.6394 | Valid Accuracy:  79.5812%\n",
            "\n",
            "Validation loss has decreased (0.639434 --> 0.604736). Saving model...\n",
            "Epoch : 4 / 20\n",
            "Time to complete 4 is 0:01:28.576317\n",
            "Train Loss:  0.7236 | Train Accuracy:  77.1274%\n",
            "Valid Loss:  0.6047 | Valid Accuracy:  80.8518%\n",
            "\n",
            "Validation loss has decreased (0.604736 --> 0.590613). Saving model...\n",
            "Epoch : 5 / 20\n",
            "Time to complete 5 is 0:01:28.745610\n",
            "Train Loss:  0.6932 | Train Accuracy:  78.0347%\n",
            "Valid Loss:  0.5906 | Valid Accuracy:  81.3813%\n",
            "\n",
            "Validation loss has decreased (0.590613 --> 0.578041). Saving model...\n",
            "Epoch : 6 / 20\n",
            "Time to complete 6 is 0:01:28.309078\n",
            "Train Loss:  0.6681 | Train Accuracy:  78.9432%\n",
            "Valid Loss:  0.5780 | Valid Accuracy:  81.5519%\n",
            "\n",
            "Validation loss has decreased (0.578041 --> 0.560184). Saving model...\n",
            "Epoch : 7 / 20\n",
            "Time to complete 7 is 0:01:28.200552\n",
            "Train Loss:  0.6475 | Train Accuracy:  79.6027%\n",
            "Valid Loss:  0.5602 | Valid Accuracy:  82.2048%\n",
            "\n",
            "Validation loss has decreased (0.560184 --> 0.548907). Saving model...\n",
            "Epoch : 8 / 20\n",
            "Time to complete 8 is 0:01:29.762557\n",
            "Train Loss:  0.6288 | Train Accuracy:  80.1217%\n",
            "Valid Loss:  0.5489 | Valid Accuracy:  82.6107%\n",
            "\n",
            "Validation loss has decreased (0.548907 --> 0.543776). Saving model...\n",
            "Epoch : 9 / 20\n",
            "Time to complete 9 is 0:01:29.765900\n",
            "Train Loss:  0.6110 | Train Accuracy:  80.7015%\n",
            "Valid Loss:  0.5438 | Valid Accuracy:  82.5813%\n",
            "\n",
            "Validation loss has decreased (0.543776 --> 0.536232). Saving model...\n",
            "Epoch : 10 / 20\n",
            "Time to complete 10 is 0:01:29.441538\n",
            "Train Loss:  0.5973 | Train Accuracy:  81.1381%\n",
            "Valid Loss:  0.5362 | Valid Accuracy:  82.9696%\n",
            "\n",
            "Validation loss has decreased (0.536232 --> 0.522871). Saving model...\n",
            "Epoch : 11 / 20\n",
            "Time to complete 11 is 0:01:28.517042\n",
            "Train Loss:  0.5840 | Train Accuracy:  81.4682%\n",
            "Valid Loss:  0.5229 | Valid Accuracy:  83.2284%\n",
            "\n",
            "Validation loss has decreased (0.522871 --> 0.509175). Saving model...\n",
            "Epoch : 12 / 20\n",
            "Time to complete 12 is 0:01:28.939615\n",
            "Train Loss:  0.5685 | Train Accuracy:  82.0650%\n",
            "Valid Loss:  0.5092 | Valid Accuracy:  83.8814%\n",
            "\n",
            "Early stoping counter: 1 out of 5\n",
            "Epoch : 13 / 20\n",
            "Time to complete 13 is 0:01:29.036023\n",
            "Train Loss:  0.5603 | Train Accuracy:  82.2133%\n",
            "Valid Loss:  0.5097 | Valid Accuracy:  83.8932%\n",
            "\n",
            "Validation loss has decreased (0.509175 --> 0.503600). Saving model...\n",
            "Epoch : 14 / 20\n",
            "Time to complete 14 is 0:01:29.435028\n",
            "Train Loss:  0.5495 | Train Accuracy:  82.5846%\n",
            "Valid Loss:  0.5036 | Valid Accuracy:  84.0226%\n",
            "\n",
            "Validation loss has decreased (0.503600 --> 0.497045). Saving model...\n",
            "Epoch : 15 / 20\n",
            "Time to complete 15 is 0:01:29.668937\n",
            "Train Loss:  0.5394 | Train Accuracy:  82.8493%\n",
            "Valid Loss:  0.4970 | Valid Accuracy:  84.0755%\n",
            "\n",
            "Validation loss has decreased (0.497045 --> 0.483569). Saving model...\n",
            "Epoch : 16 / 20\n",
            "Time to complete 16 is 0:01:29.106426\n",
            "Train Loss:  0.5325 | Train Accuracy:  83.0997%\n",
            "Valid Loss:  0.4836 | Valid Accuracy:  84.4638%\n",
            "\n",
            "Validation loss has decreased (0.483569 --> 0.475371). Saving model...\n",
            "Epoch : 17 / 20\n",
            "Time to complete 17 is 0:01:30.383227\n",
            "Train Loss:  0.5240 | Train Accuracy:  83.3585%\n",
            "Valid Loss:  0.4754 | Valid Accuracy:  84.8403%\n",
            "\n",
            "Early stoping counter: 1 out of 5\n",
            "Epoch : 18 / 20\n",
            "Time to complete 18 is 0:01:29.783428\n",
            "Train Loss:  0.5166 | Train Accuracy:  83.5834%\n",
            "Valid Loss:  0.4806 | Valid Accuracy:  84.4991%\n",
            "\n",
            "Validation loss has decreased (0.475371 --> 0.466566). Saving model...\n",
            "Epoch : 19 / 20\n",
            "Time to complete 19 is 0:01:29.797050\n",
            "Train Loss:  0.5071 | Train Accuracy:  83.8056%\n",
            "Valid Loss:  0.4666 | Valid Accuracy:  85.0109%\n",
            "\n",
            "Validation loss has decreased (0.466566 --> 0.464801). Saving model...\n",
            "Epoch : 20 / 20\n",
            "Time to complete 20 is 0:01:30.722929\n",
            "Train Loss:  0.5013 | Train Accuracy:  84.1213%\n",
            "Valid Loss:  0.4648 | Valid Accuracy:  85.0932%\n",
            "\n"
          ]
        }
      ],
      "source": [
        "example_ct_train, batch_ct_train, example_ct_valid, batch_ct_valid = 0, 0, 0, 0\n",
        "train_loss_history, train_acc_history, valid_loss_history, valid_acc_history = train_loop(train_loader, valid_loader, model_stack_exchange, loss_function, optimizer, \n",
        "                                                                                          wandb.config.EPOCHS, device,\n",
        "                                                                                          wandb.config.PATIENCE, wandb.config.EARLY_STOPPING,\n",
        "                                                                                          wandb.config.FILE_MODEL)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNODEpa2h0yc"
      },
      "source": [
        "## Add Visulaization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXO9Cqxb7JN_"
      },
      "source": [
        "### Add Loss plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "Q-Vgzk5ppgbR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "b3818229-bc29-4dd2-e4ee-73379f37e9b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/plotly/matplotlylib/renderer.py:613: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# Plot the train loss and test loss per iteration\n",
        "fig = plt.figure(0)\n",
        "plt.plot(train_loss_history, label = 'train loss')\n",
        "plt.plot(valid_loss_history, label = 'valid loss')\n",
        "plt.legend()\n",
        "\n",
        "# Log the plot to W&B\n",
        "wandb.log({\"train-test loss per epoch\": fig})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWCLH47azD6j"
      },
      "source": [
        "# **Accuracy and Predictions**\n",
        "\n",
        "Now we have final values for weights and bias after training the model. We will use these values to make predictions on the test dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzDX4D6EvcVC"
      },
      "source": [
        "## Function to get predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "M6KZqsnqQFVu"
      },
      "outputs": [],
      "source": [
        "def get_acc_pred(data_loader, model):\n",
        "  \"\"\" \n",
        "  Function to get predictions for a given test set and calculate accuracy.\n",
        "  Input: Iterator to the test set.\n",
        "  Output: Prections and Accuracy for test set.\n",
        "  \"\"\"\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    # Array to store predicted labels\n",
        "    predictions = torch.Tensor()\n",
        "    predictions = predictions.to(device)\n",
        "\n",
        "    # Array to store actual labels\n",
        "    y = torch.Tensor()\n",
        "    y = y.to(device)\n",
        "    # Iterate over batches from test set\n",
        "    for inputs, targets, offsets in data_loader:\n",
        "      \n",
        "      # move inputs and outputs to GPUs\n",
        "      inputs = inputs.to(device)\n",
        "      targets = targets.to(device)\n",
        "      offsets = offsets.to(device)\n",
        "\n",
        "      # Calculated the predicted labels\n",
        "      output = model(inputs, offsets)\n",
        "\n",
        "      # Choose the label with maximum probability\n",
        "      indices = torch.argmax(output, dim = 1)\n",
        "\n",
        "      # Add the predicted labels to the array\n",
        "      predictions = torch.cat((predictions, indices)) \n",
        "\n",
        "      # Add the actual labels to the array\n",
        "      y = torch.cat((y, targets)) \n",
        "\n",
        "    # Check for complete dataset if actual and predicted labels are same or not\n",
        "    # Calculate accuracy\n",
        "    acc = (predictions == y).float().mean()\n",
        "\n",
        "  # Return array containing predictions and accuracy\n",
        "  return predictions, acc\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lK-g-bSTvkl8"
      },
      "source": [
        "## Load saved model from file "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "QVT_qlEivpER",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "7e60c63e-eea6-41b2-b64d-2df2702241a4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "model_nn = MLPCustom(wandb.config.VOCAB_SIZE, wandb.config.HIDDEN_SIZES_LIST, wandb.config.DPROBS_LIST, wandb.config.BATCHNORM_BINARY, \n",
        "           wandb.config.OUTPUT_DIM, non_linearity)\n",
        "model_nn.to(device)\n",
        "model_nn.load_state_dict(torch.load(wandb.config.FILE_MODEL))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "rKNCkt_XeCZ1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "1d39f682-bbf7-4c1a-ff80-5e7afc0143dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/NLP/models/stack_exchange_2_hidden_layers.pt\n"
          ]
        }
      ],
      "source": [
        "print(wandb.config.FILE_MODEL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "6mZ5tlp53hi7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "c90b9961-9d89-466e-bcb9-0d38a4548552"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning:\n",
            "\n",
            "This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Get the prediction and accuracy for the test dataset\n",
        "predictions, acc_test = get_acc_pred(test_loader, model_nn)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print Accuracy for test dataset\n",
        "print(acc_test * 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "76HZ3xGNqIAO",
        "outputId": "a0c4d76d-eb20-47ed-a381-86bb1b52de44"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(85.1493)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jgOQMtJ8VFYf"
      },
      "source": [
        "**We have obtained 85 % accuracy on test dataset.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "caRp4G3ov5fp"
      },
      "source": [
        "## **Visualizations on Predictions**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZf0pSyQV32m"
      },
      "source": [
        "Now, we will make some visualizations for the predictions that we obtained."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5sQH0GvxXnam"
      },
      "source": [
        "We will construct a `confusion matrix` which will help us to visualize the performance of our classification model on the test dataset as we know the true values for the test data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "NaiRaPuQYYIV"
      },
      "outputs": [],
      "source": [
        "# Get an array containing actual labels\n",
        "testing_labels = testset.y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "bVbWdA7XOuct"
      },
      "outputs": [],
      "source": [
        "# Define the values for classes\n",
        "classes = ['c#', 'java', 'php', 'javascript', 'android', 'jquery', 'c++', 'python', 'iphone', 'asp.net']\n",
        "\n",
        "# Log a confusion matrix to W&B\n",
        "wandb.log({\"conf_mat\" : wandb.plot.confusion_matrix(\n",
        "                        probs = None,\n",
        "                        y_true = testing_labels,\n",
        "                        preds = predictions.to('cpu').numpy(),\n",
        "                        class_names = classes)})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "tKJE8weMG4WN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372,
          "referenced_widgets": [
            "07b7782692744c00954bafc366848715",
            "7058189b1d29443bb3eb3da59c1fe35e",
            "b4273f95853c44ebb48bdbc3c350b753",
            "6919aef0fecd4567be7ed36afe3f4417",
            "93f7357bcaf74b069e5c653a3b09a7b5",
            "ad9b3f32eee940bb8fd2f08d3294e532",
            "ecb87e72498d423dab001e9b1df88727",
            "838bae5b82d446f9b626d00a5834b44d"
          ]
        },
        "outputId": "67ac8c5d-c155-4e65-8d45-ba761550c852"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.018 MB of 0.018 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "07b7782692744c00954bafc366848715"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Train Batch Acc :</td><td>▁▄▅▅▆▆▆▆▆▆▆▆▆▆▇▇▆▇▆▆▇▇▇▇▇▇▇▇█▆▇▇▇▇▇▇▇██▇</td></tr><tr><td>Train Batch Loss  :</td><td>█▅▄▄▄▄▄▃▃▄▃▃▄▃▂▂▃▂▃▃▃▂▃▂▂▃▂▂▁▃▃▂▃▁▂▂▂▂▁▂</td></tr><tr><td>Train epoch Acc :</td><td>▁▄▅▆▆▆▆▇▇▇▇▇▇▇██████</td></tr><tr><td>Train epoch Loss :</td><td>█▅▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>Valid Batch Accuracy :</td><td>▁▂▅▄▄▆▃▄▃▅▅▅▇▅▅▄▆▆▆▅▅▆▇▇▃▅▆▅▅▇▇█▆█▇▆█▇▇▇</td></tr><tr><td>Valid Batch Loss  :</td><td>██▅▇▇▄▆▆█▄▄▅▁▅▄▆▃▂▃▆▄▃▂▃▅▄▃▄▃▁▂▁▄▂▂▂▂▂▁▃</td></tr><tr><td>Valid epoch Acc :</td><td>▁▂▃▄▅▅▅▆▆▆▆▇▇▇▇▇█▇██</td></tr><tr><td>Valid epoch Loss :</td><td>█▇▆▅▄▄▄▃▃▃▃▂▂▂▂▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Train Batch Acc :</td><td>0.85547</td></tr><tr><td>Train Batch Loss  :</td><td>0.47444</td></tr><tr><td>Train epoch Acc :</td><td>0.84121</td></tr><tr><td>Train epoch Loss :</td><td>0.50129</td></tr><tr><td>Valid Batch Accuracy :</td><td>0.85547</td></tr><tr><td>Valid Batch Loss  :</td><td>0.49636</td></tr><tr><td>Valid epoch Acc :</td><td>0.85093</td></tr><tr><td>Valid epoch Loss :</td><td>0.4648</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">Embed_2_hidden_layers</strong>: <a href=\"https://wandb.ai/arulchak/NLP_MLP_Stack_Exchange/runs/2rohzf2j\" target=\"_blank\">https://wandb.ai/arulchak/NLP_MLP_Stack_Exchange/runs/2rohzf2j</a><br/>Synced 5 W&B file(s), 3 media file(s), 1 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20220410_221011-2rohzf2j/logs</code>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "7QbaUvRF8LaE"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "Arul_HW5.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "07b7782692744c00954bafc366848715": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7058189b1d29443bb3eb3da59c1fe35e",
              "IPY_MODEL_b4273f95853c44ebb48bdbc3c350b753"
            ],
            "layout": "IPY_MODEL_6919aef0fecd4567be7ed36afe3f4417"
          }
        },
        "7058189b1d29443bb3eb3da59c1fe35e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_93f7357bcaf74b069e5c653a3b09a7b5",
            "placeholder": "​",
            "style": "IPY_MODEL_ad9b3f32eee940bb8fd2f08d3294e532",
            "value": "0.074 MB of 0.074 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "b4273f95853c44ebb48bdbc3c350b753": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ecb87e72498d423dab001e9b1df88727",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_838bae5b82d446f9b626d00a5834b44d",
            "value": 1
          }
        },
        "6919aef0fecd4567be7ed36afe3f4417": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93f7357bcaf74b069e5c653a3b09a7b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad9b3f32eee940bb8fd2f08d3294e532": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ecb87e72498d423dab001e9b1df88727": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "838bae5b82d446f9b626d00a5834b44d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}